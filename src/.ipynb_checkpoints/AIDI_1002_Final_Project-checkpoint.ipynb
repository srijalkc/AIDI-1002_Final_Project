{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432e3caf-154d-4d66-8f39-c58b537738b2",
   "metadata": {},
   "source": [
    "## This is the main file that is used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18f7596-0100-4ccf-82a5-8dc452993121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RNN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast_5 (\u001b[38;5;33mCast\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │       \u001b[38;5;34m110,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │           \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m55,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │        \u001b[38;5;34m27,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m48\u001b[0m)     │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RNN (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │        \u001b[38;5;34m32,270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m15\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228,653</span> (893.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m228,653\u001b[0m (893.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,981</span> (890.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m227,981\u001b[0m (890.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> (2.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m672\u001b[0m (2.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m51/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 845ms/step - accuracy: 0.5450 - loss: 2.1457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:56:25.091109: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.0407715, expected -nan\n",
      "2024-12-08 22:56:25.091128: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.0421143, expected -nan\n",
      "2024-12-08 22:56:25.091134: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.0412292, expected -nan\n",
      "2024-12-08 22:56:25.091138: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.014122, expected -nan\n",
      "2024-12-08 22:56:25.091143: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.0766602, expected -nan\n",
      "2024-12-08 22:56:25.091147: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 10: 0.00381851, expected -nan\n",
      "2024-12-08 22:56:25.091152: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 12: 0.0513916, expected -nan\n",
      "2024-12-08 22:56:25.091156: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 14: 0.0935669, expected -nan\n",
      "2024-12-08 22:56:25.091160: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 16: 0.0162964, expected -nan\n",
      "2024-12-08 22:56:25.091165: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 18: 0.0966187, expected -nan\n",
      "2024-12-08 22:56:25.091174: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,36,256,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,1]{3,2,1,0}, f16[128,3,3,1]{3,2,1,0}, f16[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:25.091182: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:25.091186: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:25.091189: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:25.091192: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:25.091198: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:25.609296: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.34863, expected -nan\n",
      "2024-12-08 22:56:25.609377: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.37695, expected 0\n",
      "2024-12-08 22:56:25.609402: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.37305, expected -nan\n",
      "2024-12-08 22:56:25.609426: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.41016, expected 0\n",
      "2024-12-08 22:56:25.609446: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.3623, expected -nan\n",
      "2024-12-08 22:56:25.609469: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.40625, expected 0\n",
      "2024-12-08 22:56:25.609489: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.42578, expected -nan\n",
      "2024-12-08 22:56:25.609511: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.43652, expected 0\n",
      "2024-12-08 22:56:25.609531: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.41016, expected -nan\n",
      "2024-12-08 22:56:25.609553: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.42969, expected 0\n",
      "2024-12-08 22:56:25.609600: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,36,256,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,128]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}, f16[96]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=0,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:25.609636: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:25.609656: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:25.609672: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:25.609689: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:25.609724: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:25.890094: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.34863, expected -nan\n",
      "2024-12-08 22:56:25.890117: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.37695, expected 0\n",
      "2024-12-08 22:56:25.890122: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.37305, expected -nan\n",
      "2024-12-08 22:56:25.890127: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.41016, expected 0\n",
      "2024-12-08 22:56:25.890130: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.3623, expected -nan\n",
      "2024-12-08 22:56:25.890135: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.40625, expected 0\n",
      "2024-12-08 22:56:25.890139: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.42578, expected -nan\n",
      "2024-12-08 22:56:25.890143: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.43652, expected 0\n",
      "2024-12-08 22:56:25.890146: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.41016, expected -nan\n",
      "2024-12-08 22:56:25.890151: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.42969, expected 0\n",
      "2024-12-08 22:56:25.890163: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,36,256,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,128]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}, f16[96]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=0,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=4,k4=2,k5=4,k6=3,k7=2}\n",
      "2024-12-08 22:56:25.890171: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:25.890175: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:25.890178: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:25.890181: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:25.890188: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:27.917675: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.04883, expected -nan\n",
      "2024-12-08 22:56:27.917697: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.02832, expected 0\n",
      "2024-12-08 22:56:27.917703: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.00879, expected -nan\n",
      "2024-12-08 22:56:27.917709: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.09082, expected 0\n",
      "2024-12-08 22:56:27.917714: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.05176, expected -nan\n",
      "2024-12-08 22:56:27.917719: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.11914, expected 0\n",
      "2024-12-08 22:56:27.917724: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.04004, expected -nan\n",
      "2024-12-08 22:56:27.917729: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.09668, expected 0\n",
      "2024-12-08 22:56:27.917734: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.05957, expected -nan\n",
      "2024-12-08 22:56:27.917739: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.0918, expected 0\n",
      "2024-12-08 22:56:27.917749: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,18,32,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,18,32,96]{3,2,1,0}, f16[64,3,3,96]{3,2,1,0}, f16[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=4,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=4,k4=2,k5=4,k6=3,k7=2}\n",
      "2024-12-08 22:56:27.917758: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:27.917763: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:27.917767: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:27.917771: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:27.917777: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:27.929368: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.04883, expected -nan\n",
      "2024-12-08 22:56:27.929391: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.02832, expected 0\n",
      "2024-12-08 22:56:27.929399: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.00879, expected -nan\n",
      "2024-12-08 22:56:27.929406: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.09082, expected 0\n",
      "2024-12-08 22:56:27.929412: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.05176, expected -nan\n",
      "2024-12-08 22:56:27.929419: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.11914, expected 0\n",
      "2024-12-08 22:56:27.929425: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.04004, expected -nan\n",
      "2024-12-08 22:56:27.929433: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.09668, expected 0\n",
      "2024-12-08 22:56:27.929439: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.05957, expected -nan\n",
      "2024-12-08 22:56:27.929446: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.0918, expected 0\n",
      "2024-12-08 22:56:27.929460: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,18,32,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,18,32,96]{3,2,1,0}, f16[64,3,3,96]{3,2,1,0}, f16[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=4,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:27.929472: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:27.929479: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:27.929484: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:27.929489: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:27.929498: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:28.288636: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.759277, expected -nan\n",
      "2024-12-08 22:56:28.288665: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 0.699219, expected 0\n",
      "2024-12-08 22:56:28.288675: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.784668, expected -nan\n",
      "2024-12-08 22:56:28.288682: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 0.662109, expected 0\n",
      "2024-12-08 22:56:28.288689: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.749512, expected -nan\n",
      "2024-12-08 22:56:28.288696: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.700195, expected 0\n",
      "2024-12-08 22:56:28.288703: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.798828, expected -nan\n",
      "2024-12-08 22:56:28.288711: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.686035, expected 0\n",
      "2024-12-08 22:56:28.288717: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.699219, expected -nan\n",
      "2024-12-08 22:56:28.288724: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.759277, expected 0\n",
      "2024-12-08 22:56:28.288739: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,18,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,18,32,64]{3,2,1,0}, f16[48,3,3,64]{3,2,1,0}, f16[48]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=8,k13=1,k14=0,k18=0,k23=0} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:28.288750: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:28.288756: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:28.288762: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:28.288767: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:28.288775: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:28.297761: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.759277, expected -nan\n",
      "2024-12-08 22:56:28.297830: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 0.699219, expected 0\n",
      "2024-12-08 22:56:28.297858: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.784668, expected -nan\n",
      "2024-12-08 22:56:28.297882: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 0.662109, expected 0\n",
      "2024-12-08 22:56:28.297905: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.749512, expected -nan\n",
      "2024-12-08 22:56:28.297928: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.700195, expected 0\n",
      "2024-12-08 22:56:28.297950: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.798828, expected -nan\n",
      "2024-12-08 22:56:28.297973: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.686035, expected 0\n",
      "2024-12-08 22:56:28.297995: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.699219, expected -nan\n",
      "2024-12-08 22:56:28.298018: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.759277, expected 0\n",
      "2024-12-08 22:56:28.298062: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,18,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,18,32,64]{3,2,1,0}, f16[48,3,3,64]{3,2,1,0}, f16[48]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=8,k13=1,k14=0,k18=0,k23=0} vs eng4{k2=4,k4=2,k5=4,k6=3,k7=2}\n",
      "2024-12-08 22:56:28.298099: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:28.298128: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:28.298164: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:28.298187: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:28.298213: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:28.533755: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.481689, expected -nan\n",
      "2024-12-08 22:56:28.533834: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 0.491943, expected 0\n",
      "2024-12-08 22:56:28.533864: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.453613, expected -nan\n",
      "2024-12-08 22:56:28.533889: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 0.505859, expected 0\n",
      "2024-12-08 22:56:28.533913: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.479736, expected -nan\n",
      "2024-12-08 22:56:28.533936: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.559082, expected 0\n",
      "2024-12-08 22:56:28.533960: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.486084, expected -nan\n",
      "2024-12-08 22:56:28.533983: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.507324, expected 0\n",
      "2024-12-08 22:56:28.534005: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.512695, expected -nan\n",
      "2024-12-08 22:56:28.534028: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.533691, expected 0\n",
      "2024-12-08 22:56:28.534072: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,18,32,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,18,32,48]{3,2,1,0}, f16[48,3,3,64]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng30{k2=5,k13=1,k14=0,k23=0} vs eng18{k2=4,k4=1,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:28.534110: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:28.534131: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:28.534148: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:28.534165: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:28.534191: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:28.692667: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.619629, expected -nan\n",
      "2024-12-08 22:56:28.692738: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 0.659668, expected 0\n",
      "2024-12-08 22:56:28.692769: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.657715, expected -nan\n",
      "2024-12-08 22:56:28.692795: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 0.689453, expected 0\n",
      "2024-12-08 22:56:28.692818: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.669922, expected -nan\n",
      "2024-12-08 22:56:28.692842: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.699219, expected 0\n",
      "2024-12-08 22:56:28.692865: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.674805, expected -nan\n",
      "2024-12-08 22:56:28.692888: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.646484, expected 0\n",
      "2024-12-08 22:56:28.692910: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.644531, expected -nan\n",
      "2024-12-08 22:56:28.692933: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.677246, expected 0\n",
      "2024-12-08 22:56:28.692976: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,18,32,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,18,32,64]{3,2,1,0}, f16[64,3,3,96]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng30{k2=0,k13=0,k14=0,k23=0} vs eng18{k2=4,k4=1,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:28.693028: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:28.693071: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:28.693108: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:28.693137: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:28.693174: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:29.516735: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.04883, expected -nan\n",
      "2024-12-08 22:56:29.516759: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.01172, expected 0\n",
      "2024-12-08 22:56:29.516764: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.06152, expected -nan\n",
      "2024-12-08 22:56:29.516769: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1, expected 0\n",
      "2024-12-08 22:56:29.516774: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.959473, expected -nan\n",
      "2024-12-08 22:56:29.516779: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.990234, expected 0\n",
      "2024-12-08 22:56:29.516784: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.979004, expected -nan\n",
      "2024-12-08 22:56:29.516789: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.990234, expected 0\n",
      "2024-12-08 22:56:29.516794: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.973145, expected -nan\n",
      "2024-12-08 22:56:29.516799: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.983398, expected 0\n",
      "2024-12-08 22:56:29.516809: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[10,36,256,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,96]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng30{k2=0,k13=0,k14=0,k23=0} vs eng18{k2=4,k4=1,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:29.516818: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:29.516822: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:29.516826: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:29.516829: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:29.516836: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:31.875733: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f16[10,36,256,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,96]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-12-08 22:56:38.478495: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 7.602837355s\n",
      "Trying algorithm eng0{} for conv (f16[10,36,256,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,96]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-12-08 22:56:43.124104: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{} for conv (f16[96,3,3,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,128]{3,2,1,0}, f16[10,36,256,96]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-12-08 22:56:45.368433: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.244443469s\n",
      "Trying algorithm eng19{} for conv (f16[96,3,3,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,36,256,128]{3,2,1,0}, f16[10,36,256,96]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5520 - loss: 2.0254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:56:51.601553: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.00627899, expected -nan\n",
      "2024-12-08 22:56:51.601574: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.0679932, expected -nan\n",
      "2024-12-08 22:56:51.601579: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.0516052, expected -nan\n",
      "2024-12-08 22:56:51.601584: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.0992432, expected -nan\n",
      "2024-12-08 22:56:51.601588: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.045105, expected -nan\n",
      "2024-12-08 22:56:51.601592: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 10: 0.0713501, expected -nan\n",
      "2024-12-08 22:56:51.601596: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 12: 0.0951538, expected -nan\n",
      "2024-12-08 22:56:51.601601: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 14: 0.102051, expected -nan\n",
      "2024-12-08 22:56:51.601605: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 16: 0.0806885, expected -nan\n",
      "2024-12-08 22:56:51.601609: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 18: 0.036377, expected -nan\n",
      "2024-12-08 22:56:51.601617: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,36,256,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,36,256,1]{3,2,1,0}, f16[128,3,3,1]{3,2,1,0}, f16[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:51.601624: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:51.601628: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:51.601631: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:51.601634: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:51.601639: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:51.762744: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.40234, expected -nan\n",
      "2024-12-08 22:56:51.762785: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.36621, expected 0\n",
      "2024-12-08 22:56:51.762789: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.30664, expected -nan\n",
      "2024-12-08 22:56:51.762794: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.36719, expected 0\n",
      "2024-12-08 22:56:51.762798: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.37793, expected -nan\n",
      "2024-12-08 22:56:51.762802: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.41211, expected 0\n",
      "2024-12-08 22:56:51.762806: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.40137, expected -nan\n",
      "2024-12-08 22:56:51.762810: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.46582, expected 0\n",
      "2024-12-08 22:56:51.762814: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.41895, expected -nan\n",
      "2024-12-08 22:56:51.762818: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.36426, expected 0\n",
      "2024-12-08 22:56:51.762825: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,36,256,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,36,256,128]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}, f16[96]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=0,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:51.762832: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:51.762836: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:51.762839: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:51.762842: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:51.762847: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:51.864484: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 1.40234, expected -nan\n",
      "2024-12-08 22:56:51.864507: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.36621, expected 0\n",
      "2024-12-08 22:56:51.864512: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.30664, expected -nan\n",
      "2024-12-08 22:56:51.864517: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.36719, expected 0\n",
      "2024-12-08 22:56:51.864521: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.37793, expected -nan\n",
      "2024-12-08 22:56:51.864525: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.41211, expected 0\n",
      "2024-12-08 22:56:51.864529: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.40137, expected -nan\n",
      "2024-12-08 22:56:51.864533: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.46582, expected 0\n",
      "2024-12-08 22:56:51.864536: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.41895, expected -nan\n",
      "2024-12-08 22:56:51.864541: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.36426, expected 0\n",
      "2024-12-08 22:56:51.864551: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,36,256,96]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,36,256,128]{3,2,1,0}, f16[96,3,3,128]{3,2,1,0}, f16[96]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=0,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=4,k4=2,k5=4,k6=3,k7=2}\n",
      "2024-12-08 22:56:51.864558: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:51.864562: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:51.864565: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:51.864568: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:51.864574: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:52.536712: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.985352, expected -nan\n",
      "2024-12-08 22:56:52.536751: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.0498, expected 0\n",
      "2024-12-08 22:56:52.536756: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.10645, expected -nan\n",
      "2024-12-08 22:56:52.536760: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.03809, expected 0\n",
      "2024-12-08 22:56:52.536764: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.04492, expected -nan\n",
      "2024-12-08 22:56:52.536768: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.1084, expected 0\n",
      "2024-12-08 22:56:52.536772: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.02539, expected -nan\n",
      "2024-12-08 22:56:52.536776: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.0957, expected 0\n",
      "2024-12-08 22:56:52.536780: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.01172, expected -nan\n",
      "2024-12-08 22:56:52.536784: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.01465, expected 0\n",
      "2024-12-08 22:56:52.536791: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,18,32,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,18,32,96]{3,2,1,0}, f16[64,3,3,96]{3,2,1,0}, f16[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=4,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=4,k4=2,k5=4,k6=3,k7=2}\n",
      "2024-12-08 22:56:52.536797: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:52.536801: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:52.536804: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:52.536807: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:52.536812: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:52.541010: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.985352, expected -nan\n",
      "2024-12-08 22:56:52.541022: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 1.0498, expected 0\n",
      "2024-12-08 22:56:52.541048: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 1.10645, expected -nan\n",
      "2024-12-08 22:56:52.541052: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 1.03809, expected 0\n",
      "2024-12-08 22:56:52.541055: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 1.04492, expected -nan\n",
      "2024-12-08 22:56:52.541060: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 1.1084, expected 0\n",
      "2024-12-08 22:56:52.541063: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 1.02539, expected -nan\n",
      "2024-12-08 22:56:52.541067: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 1.0957, expected 0\n",
      "2024-12-08 22:56:52.541071: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 1.01172, expected -nan\n",
      "2024-12-08 22:56:52.541075: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 1.01465, expected 0\n",
      "2024-12-08 22:56:52.541103: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,18,32,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,18,32,96]{3,2,1,0}, f16[64,3,3,96]{3,2,1,0}, f16[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=4,k13=0,k14=0,k18=0,k23=0} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:52.541110: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:52.541136: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:52.541139: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:52.541165: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:52.541169: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:52.623445: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.728516, expected -nan\n",
      "2024-12-08 22:56:52.623467: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 0.693359, expected 0\n",
      "2024-12-08 22:56:52.623472: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.71582, expected -nan\n",
      "2024-12-08 22:56:52.623477: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 0.733887, expected 0\n",
      "2024-12-08 22:56:52.623481: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.685547, expected -nan\n",
      "2024-12-08 22:56:52.623486: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.696289, expected 0\n",
      "2024-12-08 22:56:52.623490: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.755859, expected -nan\n",
      "2024-12-08 22:56:52.623494: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.743164, expected 0\n",
      "2024-12-08 22:56:52.623498: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.6875, expected -nan\n",
      "2024-12-08 22:56:52.623502: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.793457, expected 0\n",
      "2024-12-08 22:56:52.623510: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,18,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,18,32,64]{3,2,1,0}, f16[48,3,3,64]{3,2,1,0}, f16[48]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=8,k13=1,k14=0,k18=0,k23=0} vs eng4{k2=0,k4=2,k5=3,k6=3,k7=2}\n",
      "2024-12-08 22:56:52.623517: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:52.623521: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:52.623524: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:52.623527: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:52.623533: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n",
      "2024-12-08 22:56:52.627041: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 0.728516, expected -nan\n",
      "2024-12-08 22:56:52.627052: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 1: 0.693359, expected 0\n",
      "2024-12-08 22:56:52.627057: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 2: 0.71582, expected -nan\n",
      "2024-12-08 22:56:52.627061: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 3: 0.733887, expected 0\n",
      "2024-12-08 22:56:52.627066: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 4: 0.685547, expected -nan\n",
      "2024-12-08 22:56:52.627070: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 5: 0.696289, expected 0\n",
      "2024-12-08 22:56:52.627074: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 6: 0.755859, expected -nan\n",
      "2024-12-08 22:56:52.627078: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 7: 0.743164, expected 0\n",
      "2024-12-08 22:56:52.627083: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 8: 0.6875, expected -nan\n",
      "2024-12-08 22:56:52.627087: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 9: 0.793457, expected 0\n",
      "2024-12-08 22:56:52.627124: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f16[4,18,32,48]{3,2,1,0}, u8[0]{0}) custom-call(f16[4,18,32,64]{3,2,1,0}, f16[48,3,3,64]{3,2,1,0}, f16[48]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng9{k2=8,k13=1,k14=0,k18=0,k23=0} vs eng4{k2=4,k4=2,k5=4,k6=3,k7=2}\n",
      "2024-12-08 22:56:52.627131: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: NVIDIA GeForce GTX 1660 Ti\n",
      "2024-12-08 22:56:52.627135: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 7.5\n",
      "2024-12-08 22:56:52.627138: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12070 (565.77.0)\n",
      "2024-12-08 22:56:52.627141: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n",
      "2024-12-08 22:56:52.627162: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.58228, saving model to modelcpnt5ba5d242-aaac-43cc-8593-e6f1d462faa8.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.5528 - loss: 2.0134 - val_accuracy: 0.5400 - val_loss: 0.5823\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7607 - loss: 0.4669\n",
      "Epoch 2: val_loss did not improve from 0.58228\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 0.7617 - loss: 0.4652 - val_accuracy: 0.6900 - val_loss: 0.6178\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9707 - loss: 0.0933\n",
      "Epoch 3: val_loss did not improve from 0.58228\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9707 - loss: 0.0930 - val_accuracy: 0.6100 - val_loss: 1.3209\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9912 - loss: 0.0313\n",
      "Epoch 4: val_loss did not improve from 0.58228\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 0.9912 - loss: 0.0313 - val_accuracy: 0.6800 - val_loss: 0.7844\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9959 - loss: 0.0161\n",
      "Epoch 5: val_loss improved from 0.58228 to 0.33532, saving model to modelcpnt5ba5d242-aaac-43cc-8593-e6f1d462faa8.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 0.9960 - loss: 0.0160 - val_accuracy: 0.8500 - val_loss: 0.3353\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9953 - loss: 0.0138\n",
      "Epoch 6: val_loss improved from 0.33532 to 0.01379, saving model to modelcpnt5ba5d242-aaac-43cc-8593-e6f1d462faa8.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9921 - loss: 0.0190\n",
      "Epoch 7: val_loss did not improve from 0.01379\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - accuracy: 0.9921 - loss: 0.0189 - val_accuracy: 0.9700 - val_loss: 0.0551\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 9.1905e-04\n",
      "Epoch 8: val_loss improved from 0.01379 to 0.01378, saving model to modelcpnt5ba5d242-aaac-43cc-8593-e6f1d462faa8.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 9.1529e-04 - val_accuracy: 0.9900 - val_loss: 0.0138\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.1125e-04\n",
      "Epoch 9: val_loss did not improve from 0.01378\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 4.0989e-04 - val_accuracy: 0.9800 - val_loss: 0.0288\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.3905e-04\n",
      "Epoch 10: val_loss improved from 0.01378 to 0.00000, saving model to modelcpnt5ba5d242-aaac-43cc-8593-e6f1d462faa8.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 2.3869e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 2.4461e-04\n",
      "Epoch 11: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 2.4642e-04 - val_accuracy: 0.9700 - val_loss: 0.0663\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.7868e-04\n",
      "Epoch 12: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 2.7882e-04 - val_accuracy: 1.0000 - val_loss: 6.8151e-06\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.6655e-04\n",
      "Epoch 13: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 2.6572e-04 - val_accuracy: 1.0000 - val_loss: 1.0404e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 3.3735e-04\n",
      "Epoch 14: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 3.3560e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 2.1456e-04\n",
      "Epoch 15: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 2.1454e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.1963e-04\n",
      "Epoch 16: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 1.1972e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.9019e-04\n",
      "Epoch 17: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.8959e-04 - val_accuracy: 1.0000 - val_loss: 3.6300e-07\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.1319e-04\n",
      "Epoch 18: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 2.1272e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.3735e-04\n",
      "Epoch 19: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.3773e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.0953e-04\n",
      "Epoch 20: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 2.0848e-04 - val_accuracy: 1.0000 - val_loss: 3.3200e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.3516e-04\n",
      "Epoch 21: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 2.3392e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 22/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.2967e-04\n",
      "Epoch 22: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.2969e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 23/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9956 - loss: 0.0259\n",
      "Epoch 23: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 0.9957 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 3.0062e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1984e-04\n",
      "Epoch 24: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1923e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 25/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.0023e-04\n",
      "Epoch 25: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 1.0040e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 26/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.0427e-04\n",
      "Epoch 26: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.0457e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 27/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 7.4446e-05\n",
      "Epoch 27: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 7.4316e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 28/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.0182e-04\n",
      "Epoch 28: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.0171e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 29/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 7.2850e-05\n",
      "Epoch 29: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 7.2897e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 30/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.2657e-04\n",
      "Epoch 30: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 1.2613e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 31/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.0600e-04\n",
      "Epoch 31: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.0541e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 32/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.8146e-05\n",
      "Epoch 32: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 4.8344e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 33/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 9.9533e-05\n",
      "Epoch 33: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 9.8937e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 34/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 6.1713e-05\n",
      "Epoch 34: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 6.1646e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 35/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 3.8538e-05\n",
      "Epoch 35: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 3.8703e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 36/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 3.3620e-05\n",
      "Epoch 36: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 3.3739e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 37/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 3.6393e-05\n",
      "Epoch 37: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 3.6556e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 38/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 9.0397e-05\n",
      "Epoch 38: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 8.9930e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 39/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 9.5475e-05\n",
      "Epoch 39: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 9.5148e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 40/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 5.2068e-05\n",
      "Epoch 40: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 5.2186e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 41/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.6209e-05\n",
      "Epoch 41: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 1.6258e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 42/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.8373e-05\n",
      "Epoch 42: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 4.8513e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 43/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 4.9791e-05\n",
      "Epoch 43: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 5.0027e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 44/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.9005e-05\n",
      "Epoch 44: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 2.9026e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 45/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 4.9932e-05\n",
      "Epoch 45: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 5.0052e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 46/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 7.3129e-05\n",
      "Epoch 46: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 7.2911e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 47/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.7823e-05\n",
      "Epoch 47: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 4.7806e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 48/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 3.0386e-05\n",
      "Epoch 48: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 3.0193e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 49/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.5957e-05\n",
      "Epoch 49: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.5997e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 50/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 3.5511e-05\n",
      "Epoch 50: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 3.5440e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 51/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 8.0524e-05\n",
      "Epoch 51: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 8.0153e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 52/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 8.5595e-06\n",
      "Epoch 52: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 8.6760e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 53/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 2.2270e-05\n",
      "Epoch 53: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 2.2665e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 54/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.3501e-05\n",
      "Epoch 54: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 4.3344e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 55/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 4.0928e-05\n",
      "Epoch 55: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 4.0871e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 56/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 8.5039e-06\n",
      "Epoch 56: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 8.5973e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 57/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 3.6044e-05\n",
      "Epoch 57: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 3.5796e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 58/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.7075e-05\n",
      "Epoch 58: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 4.6992e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 59/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.3430e-05\n",
      "Epoch 59: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 2.3474e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 60/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 3.5314e-05\n",
      "Epoch 60: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 3.5077e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.4433e-05\n",
      "Epoch 61: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 4.4474e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 5.6252e-05\n",
      "Epoch 62: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 5.6188e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 2.8423e-05\n",
      "Epoch 63: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 2.8692e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 4.3272e-05\n",
      "Epoch 64: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 4.2987e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.2080e-05\n",
      "Epoch 65: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 4.2022e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 3.6929e-05\n",
      "Epoch 66: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 3.7080e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 5.3950e-05\n",
      "Epoch 67: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 5.3956e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.4532e-05\n",
      "Epoch 68: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 2.5185e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.7285e-05\n",
      "Epoch 69: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.7360e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.1119e-05\n",
      "Epoch 70: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 2.1180e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.1375e-05\n",
      "Epoch 71: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 2.1489e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 72/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 5.5229e-05\n",
      "Epoch 72: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 5.4877e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 73/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.4326e-05\n",
      "Epoch 73: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.4319e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 74/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.4731e-05\n",
      "Epoch 74: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.4714e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 75/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.7443e-05\n",
      "Epoch 75: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.7391e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 76/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.8402e-05\n",
      "Epoch 76: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.8383e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 77/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 2.1460e-05\n",
      "Epoch 77: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 2.1501e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 78/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.4781e-05\n",
      "Epoch 78: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.4843e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 79/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 3.2592e-05\n",
      "Epoch 79: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 3.2516e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 80/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 3.2040e-05\n",
      "Epoch 80: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 3.1862e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 81/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 3.4087e-05\n",
      "Epoch 81: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 3.3946e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 82/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.7615e-05\n",
      "Epoch 82: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 1.7616e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 83/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 5.0433e-05\n",
      "Epoch 83: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 4.9954e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 84/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 2.3140e-05\n",
      "Epoch 84: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 2.3171e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 85/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 3.7091e-05\n",
      "Epoch 85: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 3.6893e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 86/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.6494e-05\n",
      "Epoch 86: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.6667e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 87/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.1806e-05\n",
      "Epoch 87: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 2.1905e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 88/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 3.8851e-05\n",
      "Epoch 88: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 3.8712e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 89/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.7800e-05\n",
      "Epoch 89: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.7829e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 90/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.2934e-05\n",
      "Epoch 90: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 4.2789e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 91/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 6.3756e-06\n",
      "Epoch 91: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 6.4123e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 92/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.0514e-05\n",
      "Epoch 92: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.0532e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 93/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 9.1761e-06\n",
      "Epoch 93: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 9.3067e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 94/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 6.2357e-05\n",
      "Epoch 94: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 6.1799e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 95/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 2.0353e-05\n",
      "Epoch 95: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 2.0483e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 96/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 3.6781e-05\n",
      "Epoch 96: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 3.6999e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 97/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 9.6551e-06\n",
      "Epoch 97: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 9.6650e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 98/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.3674e-05\n",
      "Epoch 98: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.3699e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 99/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 2.0502e-05\n",
      "Epoch 99: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 2.0632e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 100/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 9.7461e-06\n",
      "Epoch 100: val_loss did not improve from 0.00000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 9.7460e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[[0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.4357594 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        3.9754386 1.       ]\n",
      " [1.        8.3845    1.       ]\n",
      " [1.        3.816394  1.       ]\n",
      " [1.        6.841616  1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        0.9444059 1.       ]\n",
      " [1.        7.4808564 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        2.3222325 1.       ]\n",
      " [1.        3.312442  1.       ]\n",
      " [1.        5.8017273 1.       ]\n",
      " [1.        6.134237  1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.1377684 1.       ]\n",
      " [1.        1.0466657 1.       ]\n",
      " [1.        4.5950184 1.       ]\n",
      " [1.        8.197412  1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        2.9444404 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        2.3389773 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        7.3814087 1.       ]\n",
      " [1.        6.502746  1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        2.9977772 1.       ]\n",
      " [1.        5.5959854 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        2.7033617 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.2798749 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.5734217 1.       ]\n",
      " [1.        2.2683933 1.       ]\n",
      " [1.        0.9353771 1.       ]\n",
      " [1.        1.1917816 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        4.98957   1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        2.5492694 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        3.1047835 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        3.5800025 1.       ]\n",
      " [1.        1.0873711 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.2603793 1.       ]\n",
      " [1.        7.64136   1.       ]\n",
      " [1.        2.7959366 1.       ]\n",
      " [1.        1.5001423 1.       ]\n",
      " [1.        6.353179  1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        3.4543984 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        6.4435368 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.3453869 1.       ]\n",
      " [1.        2.8609335 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        3.6865084 1.       ]\n",
      " [1.        8.347785  1.       ]\n",
      " [1.        7.0316086 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.0430528 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.0507816 1.       ]\n",
      " [1.        1.1853644 1.       ]\n",
      " [1.        6.422444  1.       ]\n",
      " [1.        8.261579  1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.1304122 1.       ]\n",
      " [1.        3.5115087 1.       ]\n",
      " [0.        0.        0.       ]\n",
      " [1.        1.2606232 1.       ]\n",
      " [1.        1.5595729 1.       ]\n",
      " [1.        1.5018142 1.       ]\n",
      " [0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import uuid\n",
    "import time\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# suppressing warnings because when using tensorflow, i was getting too many gpu warnings for CUDA and cuDNN \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# checking for GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# enabling mixed precision training for better GPU utilization\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# initializing data size\n",
    "w, h = 256, 256\n",
    "# window for the first max-pool operation\n",
    "window = 7\n",
    "\n",
    "# unique identifier is generated for each run\n",
    "run_uuid = uuid.uuid4()  \n",
    "\n",
    "# this is the path for training data which is one folder up and on folder 'training' and 'validation'\n",
    "path = \"../data/training/\"\n",
    "vpath = \"../data/validation/\"\n",
    "\n",
    "# refactored data generator for better memory efficiency\n",
    "def data_generator(batch_size=10):\n",
    "    input_files = [f for f in listdir(path) if isfile(join(path, f)) and f.endswith('.bins')]\n",
    "    # we'll take random set from available data files\n",
    "    np.random.shuffle(input_files)\n",
    "    # limiting to 100 files per epoch\n",
    "    input_files = input_files[0:100]  \n",
    "    while True:\n",
    "        for i in input_files:\n",
    "            bxs = np.fromfile(path + i, dtype=np.uint16).astype('float32')\n",
    "            bxs -= bxs.mean()\n",
    "            # avoiding division by zero\n",
    "            bxs /= bxs.std() + 0.00001  \n",
    "            bxs = np.reshape(bxs, (-1, 256, 256, 1), 'C')\n",
    "            bys = np.loadtxt(path + i[:-5] + '.labels')\n",
    "            \n",
    "            for j in range(0, bxs.shape[0], batch_size):\n",
    "                yield (bxs[j:j+batch_size], bys[j:j+batch_size, 0])\n",
    "\n",
    "# updated model architecture with BatchNormalization and Dropout\n",
    "try:\n",
    "    inputs = keras.Input(shape=(w, h, 1))\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(window, 1), padding='valid')(inputs)\n",
    "    # increased number of filters and added BatchNormalization\n",
    "    x = keras.layers.Conv2D(128, 3, padding='same', activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(96, 3, padding='same', activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 8), padding='same')(x)\n",
    "    # similar changes in subsequent layers\n",
    "    x = keras.layers.Conv2D(64, 3, padding='same', activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(48, 3, padding='same', activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((3, 4), padding='same')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(14, activation='elu', name='RNN')(x)\n",
    "    # added Dropout for regularization\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "except Warning:\n",
    "    pass\n",
    "\n",
    "# updated optimizer with higher learning rate from 0.0001 to 0.0005\n",
    "opt = optimizers.RMSprop(learning_rate=0.0005, clipnorm=1.)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# loading validation data\n",
    "test_uuid = \"FA4DC2D8-C0D9-4ECB-A319-70F156E3AF31\"\n",
    "rxs = np.fromfile(vpath + test_uuid + \".bins\", dtype=np.uint16).astype('float32')\n",
    "rxs -= rxs.mean()\n",
    "rxs /= rxs.std() + 0.0001\n",
    "rxs = np.reshape(rxs, (-1, 256, 256, 1), 'C')\n",
    "rys = np.loadtxt(vpath + test_uuid + \".labels\", dtype=np.float32)\n",
    "\n",
    "validation_uuid = \"FA4DC2D8-C0D9-4ECB-A319-70F156E3AF31\"\n",
    "xs = np.fromfile(vpath + validation_uuid + \".bins\", dtype=np.uint16).astype('float32')\n",
    "xs -= xs.mean()\n",
    "xs /= xs.std() + 0.0001\n",
    "xs = np.reshape(xs, (-1, 256, 256, 1), 'C')\n",
    "ys = np.loadtxt(vpath + validation_uuid + \".labels\", dtype=np.float32)\n",
    "\n",
    "# updated DebugCallback to save plots as files\n",
    "class DebugCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predictions = model.predict(rxs)\n",
    "        res = np.concatenate((rys, predictions), -1)\n",
    "        plt.figure()\n",
    "        plt.plot(res[:, 1], res[:, 2], 'bo')\n",
    "        plt.title(f'Epoch {epoch}')\n",
    "        # please uncomment below line if you want to see the debug plot of each epoch\n",
    "        #plt.savefig(f\"debug_plot_epoch_{epoch}.png\")\n",
    "        plt.close()\n",
    "\n",
    "debug = DebugCallback()\n",
    "\n",
    "# updated ModelCheckpoint to use .keras format\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir='log', histogram_freq=1),\n",
    "    keras.callbacks.ModelCheckpoint('modelcpnt' + str(run_uuid) + '.keras', monitor='val_loss', verbose=1, save_best_only=True),\n",
    "    debug\n",
    "]\n",
    "\n",
    "# added GPU utilization and autograph decorator\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def train_model():\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.fit(data_generator(100), epochs=100, validation_data=(xs, ys[:, 0]), steps_per_epoch=60, callbacks=callbacks)\n",
    "\n",
    "train_model()\n",
    "\n",
    "# finalizing predictions and results and saving it\n",
    "predictions = model.predict(rxs)\n",
    "res = np.concatenate((rys, predictions), -1)\n",
    "plt.figure()\n",
    "plt.plot(res[:, 1], res[:, 2], 'bo')\n",
    "plt.title('Final Results')\n",
    "plt.savefig('final_results.png')\n",
    "plt.close()\n",
    "print(res)\n",
    "np.savetxt('results.txt', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea07f95-edb9-4549-853f-14b7169c46af",
   "metadata": {},
   "source": [
    "## inference.py file for testing\n",
    "### you need to create another file or just clone the repo and run this inference file using following command in your python console:\n",
    "**python inference.py modelcpnt5ba5d242-aaac-43cc-8593-e6f1d462faa8.keras ../data/validation/FA4DC2D8-C0D9-4ECB-A319-70F156E3AF31.bins**\n",
    "### or, if you trained the model yourself, here is the structure:\n",
    "**python inference.py \\<path_for_model_checkpoint> \\<path_for_respective_bins_file_to_test>**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "331d76e1-e509-4ff8-84de-23fe4215c0f3",
   "metadata": {},
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_path = sys.argv[1]\n",
    "data_path  = sys.argv[2]\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "rxs = np.fromfile(data_path, dtype=np.uint16 ).astype('float32')\n",
    "rxs -= rxs.mean()\n",
    "rxs /= rxs.std()+0.0001\n",
    "rxs = np.reshape( rxs, (-1,256,256,1), 'C')\n",
    "\n",
    "predictions = model.predict(rxs)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp_fp",
   "language": "python",
   "name": "mlp_fp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
